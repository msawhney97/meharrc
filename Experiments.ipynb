{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas.util.testing' has no attribute 'TestCase'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c26e4eaae8f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTestSorting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTestCase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mpytest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas.util.testing' has no attribute 'TestCase'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import pytest\n",
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "import pandas as pd\n",
    "from pandas.core import common as com\n",
    "from pandas import DataFrame, MultiIndex, merge, concat, Series, compat\n",
    "from pandas.util import testing as tm\n",
    "from pandas.util.testing import assert_frame_equal, assert_series_equal\n",
    "from pandas.core.sorting import (is_int64_overflow_possible,\n",
    "                                 decons_group_index,\n",
    "                                 get_group_index,\n",
    "                                 nargsort,\n",
    "                                 lexsort_indexer)\n",
    "\n",
    "\n",
    "class TestSorting(tm.TestCase):\n",
    "\n",
    "    @pytest.mark.slow\n",
    "    def test_int64_overflow(self):\n",
    "\n",
    "        B = np.concatenate((np.arange(1000), np.arange(1000), np.arange(500)))\n",
    "        A = np.arange(2500)\n",
    "        df = DataFrame({'A': A,\n",
    "                        'B': B,\n",
    "                        'C': A,\n",
    "                        'D': B,\n",
    "                        'E': A,\n",
    "                        'F': B,\n",
    "                        'G': A,\n",
    "                        'H': B,\n",
    "                        'values': np.random.randn(2500)})\n",
    "\n",
    "        lg = df.groupby(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])\n",
    "        rg = df.groupby(['H', 'G', 'F', 'E', 'D', 'C', 'B', 'A'])\n",
    "\n",
    "        left = lg.sum()['values']\n",
    "        right = rg.sum()['values']\n",
    "\n",
    "        exp_index, _ = left.index.sortlevel()\n",
    "        tm.assert_index_equal(left.index, exp_index)\n",
    "\n",
    "        exp_index, _ = right.index.sortlevel(0)\n",
    "        tm.assert_index_equal(right.index, exp_index)\n",
    "\n",
    "        tups = list(map(tuple, df[['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'\n",
    "                                   ]].values))\n",
    "        tups = com._asarray_tuplesafe(tups)\n",
    "\n",
    "        expected = df.groupby(tups).sum()['values']\n",
    "\n",
    "        for k, v in compat.iteritems(expected):\n",
    "            assert left[k] == right[k[::-1]]\n",
    "            assert left[k] == v\n",
    "        assert len(left) == len(right)\n",
    "\n",
    "    def test_int64_overflow_moar(self):\n",
    "\n",
    "        # GH9096\n",
    "        values = range(55109)\n",
    "        data = pd.DataFrame.from_dict({'a': values,\n",
    "                                       'b': values,\n",
    "                                       'c': values,\n",
    "                                       'd': values})\n",
    "        grouped = data.groupby(['a', 'b', 'c', 'd'])\n",
    "        assert len(grouped) == len(values)\n",
    "\n",
    "        arr = np.random.randint(-1 << 12, 1 << 12, (1 << 15, 5))\n",
    "        i = np.random.choice(len(arr), len(arr) * 4)\n",
    "        arr = np.vstack((arr, arr[i]))  # add sume duplicate rows\n",
    "\n",
    "        i = np.random.permutation(len(arr))\n",
    "        arr = arr[i]  # shuffle rows\n",
    "\n",
    "        df = DataFrame(arr, columns=list('abcde'))\n",
    "        df['jim'], df['joe'] = np.random.randn(2, len(df)) * 10\n",
    "        gr = df.groupby(list('abcde'))\n",
    "\n",
    "        # verify this is testing what it is supposed to test!\n",
    "        assert is_int64_overflow_possible(gr.grouper.shape)\n",
    "\n",
    "        # mannually compute groupings\n",
    "        jim, joe = defaultdict(list), defaultdict(list)\n",
    "        for key, a, b in zip(map(tuple, arr), df['jim'], df['joe']):\n",
    "            jim[key].append(a)\n",
    "            joe[key].append(b)\n",
    "\n",
    "        assert len(gr) == len(jim)\n",
    "        mi = MultiIndex.from_tuples(jim.keys(), names=list('abcde'))\n",
    "\n",
    "        def aggr(func):\n",
    "            f = lambda a: np.fromiter(map(func, a), dtype='f8')\n",
    "            arr = np.vstack((f(jim.values()), f(joe.values()))).T\n",
    "            res = DataFrame(arr, columns=['jim', 'joe'], index=mi)\n",
    "            return res.sort_index()\n",
    "\n",
    "        assert_frame_equal(gr.mean(), aggr(np.mean))\n",
    "        assert_frame_equal(gr.median(), aggr(np.median))\n",
    "\n",
    "    def test_lexsort_indexer(self):\n",
    "        keys = [[nan] * 5 + list(range(100)) + [nan] * 5]\n",
    "        # orders=True, na_position='last'\n",
    "        result = lexsort_indexer(keys, orders=True, na_position='last')\n",
    "        exp = list(range(5, 105)) + list(range(5)) + list(range(105, 110))\n",
    "        tm.assert_numpy_array_equal(result, np.array(exp, dtype=np.intp))\n",
    "\n",
    "        # orders=True, na_position='first'\n",
    "        result = lexsort_indexer(keys, orders=True, na_position='first')\n",
    "        exp = list(range(5)) + list(range(105, 110)) + list(range(5, 105))\n",
    "        tm.assert_numpy_array_equal(result, np.array(exp, dtype=np.intp))\n",
    "\n",
    "        # orders=False, na_position='last'\n",
    "        result = lexsort_indexer(keys, orders=False, na_position='last')\n",
    "        exp = list(range(104, 4, -1)) + list(range(5)) + list(range(105, 110))\n",
    "        tm.assert_numpy_array_equal(result, np.array(exp, dtype=np.intp))\n",
    "\n",
    "        # orders=False, na_position='first'\n",
    "        result = lexsort_indexer(keys, orders=False, na_position='first')\n",
    "        exp = list(range(5)) + list(range(105, 110)) + list(range(104, 4, -1))\n",
    "        tm.assert_numpy_array_equal(result, np.array(exp, dtype=np.intp))\n",
    "\n",
    "    def test_nargsort(self):\n",
    "        # np.argsort(items) places NaNs last\n",
    "        items = [nan] * 5 + list(range(100)) + [nan] * 5\n",
    "        # np.argsort(items2) may not place NaNs first\n",
    "        items2 = np.array(items, dtype='O')\n",
    "\n",
    "        try:\n",
    "            # GH 2785; due to a regression in NumPy1.6.2\n",
    "            np.argsort(np.array([[1, 2], [1, 3], [1, 2]], dtype='i'))\n",
    "            np.argsort(items2, kind='mergesort')\n",
    "        except TypeError:\n",
    "            pytest.skip('requested sort not available for type')\n",
    "\n",
    "        # mergesort is the most difficult to get right because we want it to be\n",
    "        # stable.\n",
    "\n",
    "        # According to numpy/core/tests/test_multiarray, \"\"\"The number of\n",
    "        # sorted items must be greater than ~50 to check the actual algorithm\n",
    "        # because quick and merge sort fall over to insertion sort for small\n",
    "        # arrays.\"\"\"\n",
    "\n",
    "        # mergesort, ascending=True, na_position='last'\n",
    "        result = nargsort(items, kind='mergesort', ascending=True,\n",
    "                          na_position='last')\n",
    "        exp = list(range(5, 105)) + list(range(5)) + list(range(105, 110))\n",
    "        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)\n",
    "\n",
    "        # mergesort, ascending=True, na_position='first'\n",
    "        result = nargsort(items, kind='mergesort', ascending=True,\n",
    "                          na_position='first')\n",
    "        exp = list(range(5)) + list(range(105, 110)) + list(range(5, 105))\n",
    "        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)\n",
    "\n",
    "        # mergesort, ascending=False, na_position='last'\n",
    "        result = nargsort(items, kind='mergesort', ascending=False,\n",
    "                          na_position='last')\n",
    "        exp = list(range(104, 4, -1)) + list(range(5)) + list(range(105, 110))\n",
    "        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)\n",
    "\n",
    "        # mergesort, ascending=False, na_position='first'\n",
    "        result = nargsort(items, kind='mergesort', ascending=False,\n",
    "                          na_position='first')\n",
    "        exp = list(range(5)) + list(range(105, 110)) + list(range(104, 4, -1))\n",
    "        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)\n",
    "\n",
    "        # mergesort, ascending=True, na_position='last'\n",
    "        result = nargsort(items2, kind='mergesort', ascending=True,\n",
    "                          na_position='last')\n",
    "        exp = list(range(5, 105)) + list(range(5)) + list(range(105, 110))\n",
    "        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)\n",
    "\n",
    "        # mergesort, ascending=True, na_position='first'\n",
    "        result = nargsort(items2, kind='mergesort', ascending=True,\n",
    "                          na_position='first')\n",
    "        exp = list(range(5)) + list(range(105, 110)) + list(range(5, 105))\n",
    "        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)\n",
    "\n",
    "        # mergesort, ascending=False, na_position='last'\n",
    "        result = nargsort(items2, kind='mergesort', ascending=False,\n",
    "                          na_position='last')\n",
    "        exp = list(range(104, 4, -1)) + list(range(5)) + list(range(105, 110))\n",
    "        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)\n",
    "\n",
    "        # mergesort, ascending=False, na_position='first'\n",
    "        result = nargsort(items2, kind='mergesort', ascending=False,\n",
    "                          na_position='first')\n",
    "        exp = list(range(5)) + list(range(105, 110)) + list(range(104, 4, -1))\n",
    "        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)\n",
    "\n",
    "\n",
    "class TestMerge(tm.TestCase):\n",
    "\n",
    "    @pytest.mark.slow\n",
    "    def test_int64_overflow_issues(self):\n",
    "\n",
    "        # #2690, combinatorial explosion\n",
    "        df1 = DataFrame(np.random.randn(1000, 7),\n",
    "                        columns=list('ABCDEF') + ['G1'])\n",
    "        df2 = DataFrame(np.random.randn(1000, 7),\n",
    "                        columns=list('ABCDEF') + ['G2'])\n",
    "\n",
    "        # it works!\n",
    "        result = merge(df1, df2, how='outer')\n",
    "        assert len(result) == 2000\n",
    "\n",
    "        low, high, n = -1 << 10, 1 << 10, 1 << 20\n",
    "        left = DataFrame(np.random.randint(low, high, (n, 7)),\n",
    "                         columns=list('ABCDEFG'))\n",
    "        left['left'] = left.sum(axis=1)\n",
    "\n",
    "        # one-2-one match\n",
    "        i = np.random.permutation(len(left))\n",
    "        right = left.iloc[i].copy()\n",
    "        right.columns = right.columns[:-1].tolist() + ['right']\n",
    "        right.index = np.arange(len(right))\n",
    "        right['right'] *= -1\n",
    "\n",
    "        out = merge(left, right, how='outer')\n",
    "        assert len(out) == len(left)\n",
    "        assert_series_equal(out['left'], - out['right'], check_names=False)\n",
    "        result = out.iloc[:, :-2].sum(axis=1)\n",
    "        assert_series_equal(out['left'], result, check_names=False)\n",
    "        assert result.name is None\n",
    "\n",
    "        out.sort_values(out.columns.tolist(), inplace=True)\n",
    "        out.index = np.arange(len(out))\n",
    "        for how in ['left', 'right', 'outer', 'inner']:\n",
    "            assert_frame_equal(out, merge(left, right, how=how, sort=True))\n",
    "\n",
    "        # check that left merge w/ sort=False maintains left frame order\n",
    "        out = merge(left, right, how='left', sort=False)\n",
    "        assert_frame_equal(left, out[left.columns.tolist()])\n",
    "\n",
    "        out = merge(right, left, how='left', sort=False)\n",
    "        assert_frame_equal(right, out[right.columns.tolist()])\n",
    "\n",
    "        # one-2-many/none match\n",
    "        n = 1 << 11\n",
    "        left = DataFrame(np.random.randint(low, high, (n, 7)).astype('int64'),\n",
    "                         columns=list('ABCDEFG'))\n",
    "\n",
    "        # confirm that this is checking what it is supposed to check\n",
    "        shape = left.apply(Series.nunique).values\n",
    "        assert is_int64_overflow_possible(shape)\n",
    "\n",
    "        # add duplicates to left frame\n",
    "        left = concat([left, left], ignore_index=True)\n",
    "\n",
    "        right = DataFrame(np.random.randint(low, high, (n // 2, 7))\n",
    "                          .astype('int64'),\n",
    "                          columns=list('ABCDEFG'))\n",
    "\n",
    "        # add duplicates & overlap with left to the right frame\n",
    "        i = np.random.choice(len(left), n)\n",
    "        right = concat([right, right, left.iloc[i]], ignore_index=True)\n",
    "\n",
    "        left['left'] = np.random.randn(len(left))\n",
    "        right['right'] = np.random.randn(len(right))\n",
    "\n",
    "        # shuffle left & right frames\n",
    "        i = np.random.permutation(len(left))\n",
    "        left = left.iloc[i].copy()\n",
    "        left.index = np.arange(len(left))\n",
    "\n",
    "        i = np.random.permutation(len(right))\n",
    "        right = right.iloc[i].copy()\n",
    "        right.index = np.arange(len(right))\n",
    "\n",
    "        # manually compute outer merge\n",
    "        ldict, rdict = defaultdict(list), defaultdict(list)\n",
    "\n",
    "        for idx, row in left.set_index(list('ABCDEFG')).iterrows():\n",
    "            ldict[idx].append(row['left'])\n",
    "\n",
    "        for idx, row in right.set_index(list('ABCDEFG')).iterrows():\n",
    "            rdict[idx].append(row['right'])\n",
    "\n",
    "        vals = []\n",
    "        for k, lval in ldict.items():\n",
    "            rval = rdict.get(k, [np.nan])\n",
    "            for lv, rv in product(lval, rval):\n",
    "                vals.append(k + tuple([lv, rv]))\n",
    "\n",
    "        for k, rval in rdict.items():\n",
    "            if k not in ldict:\n",
    "                for rv in rval:\n",
    "                    vals.append(k + tuple([np.nan, rv]))\n",
    "\n",
    "        def align(df):\n",
    "            df = df.sort_values(df.columns.tolist())\n",
    "            df.index = np.arange(len(df))\n",
    "            return df\n",
    "\n",
    "        def verify_order(df):\n",
    "            kcols = list('ABCDEFG')\n",
    "            assert_frame_equal(df[kcols].copy(),\n",
    "                               df[kcols].sort_values(kcols, kind='mergesort'))\n",
    "\n",
    "        out = DataFrame(vals, columns=list('ABCDEFG') + ['left', 'right'])\n",
    "        out = align(out)\n",
    "\n",
    "        jmask = {'left': out['left'].notnull(),\n",
    "                 'right': out['right'].notnull(),\n",
    "                 'inner': out['left'].notnull() & out['right'].notnull(),\n",
    "                 'outer': np.ones(len(out), dtype='bool')}\n",
    "\n",
    "        for how in 'left', 'right', 'outer', 'inner':\n",
    "            mask = jmask[how]\n",
    "            frame = align(out[mask].copy())\n",
    "            assert mask.all() ^ mask.any() or how == 'outer'\n",
    "\n",
    "            for sort in [False, True]:\n",
    "                res = merge(left, right, how=how, sort=sort)\n",
    "                if sort:\n",
    "                    verify_order(res)\n",
    "\n",
    "                # as in GH9092 dtypes break with outer/right join\n",
    "                assert_frame_equal(frame, align(res),\n",
    "                                   check_dtype=how not in ('right', 'outer'))\n",
    "\n",
    "\n",
    "def test_decons():\n",
    "\n",
    "    def testit(label_list, shape):\n",
    "        group_index = get_group_index(label_list, shape, sort=True, xnull=True)\n",
    "        label_list2 = decons_group_index(group_index, shape)\n",
    "\n",
    "        for a, b in zip(label_list, label_list2):\n",
    "            assert (np.array_equal(a, b))\n",
    "\n",
    "    shape = (4, 5, 6)\n",
    "    label_list = [np.tile([0, 1, 2, 3, 0, 1, 2, 3], 100), np.tile(\n",
    "        [0, 2, 4, 3, 0, 1, 2, 3], 100), np.tile(\n",
    "            [5, 1, 0, 2, 3, 0, 5, 4], 100)]\n",
    "    testit(label_list, shape)\n",
    "\n",
    "    shape = (10000, 10000)\n",
    "    label_list = [np.tile(np.arange(10000), 5), np.tile(np.arange(10000), 5)]\n",
    "    testit(label_list, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.util.validators'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0473831c8dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmove_into_mutable_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBadMove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstolenbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m from pandas.util.validators import (validate_args, validate_kwargs,\n\u001b[0m\u001b[1;32m     12\u001b[0m                                     \u001b[0mvalidate_args_and_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                     validate_bool_kwarg)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas.util.validators'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import os\n",
    "import locale\n",
    "import codecs\n",
    "import sys\n",
    "from uuid import uuid4\n",
    "from collections import OrderedDict\n",
    "\n",
    "import pytest\n",
    "from pandas.util._move import move_into_mutable_buffer, BadMove, stolenbuf\n",
    "from pandas.util.decorators import deprecate_kwarg\n",
    "from pandas.util.validators import (validate_args, validate_kwargs,\n",
    "                                    validate_args_and_kwargs,\n",
    "                                    validate_bool_kwarg)\n",
    "\n",
    "import pandas.util.testing as tm\n",
    "\n",
    "CURRENT_LOCALE = locale.getlocale()\n",
    "LOCALE_OVERRIDE = os.environ.get('LOCALE_OVERRIDE', None)\n",
    "\n",
    "\n",
    "class TestDecorators(tm.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        @deprecate_kwarg('old', 'new')\n",
    "        def _f1(new=False):\n",
    "            return new\n",
    "\n",
    "        @deprecate_kwarg('old', 'new', {'yes': True, 'no': False})\n",
    "        def _f2(new=False):\n",
    "            return new\n",
    "\n",
    "        @deprecate_kwarg('old', 'new', lambda x: x + 1)\n",
    "        def _f3(new=0):\n",
    "            return new\n",
    "\n",
    "        self.f1 = _f1\n",
    "        self.f2 = _f2\n",
    "        self.f3 = _f3\n",
    "\n",
    "    def test_deprecate_kwarg(self):\n",
    "        x = 78\n",
    "        with tm.assert_produces_warning(FutureWarning):\n",
    "            result = self.f1(old=x)\n",
    "        self.assertIs(result, x)\n",
    "        with tm.assert_produces_warning(None):\n",
    "            self.f1(new=x)\n",
    "\n",
    "    def test_dict_deprecate_kwarg(self):\n",
    "        x = 'yes'\n",
    "        with tm.assert_produces_warning(FutureWarning):\n",
    "            result = self.f2(old=x)\n",
    "        self.assertEqual(result, True)\n",
    "\n",
    "    def test_missing_deprecate_kwarg(self):\n",
    "        x = 'bogus'\n",
    "        with tm.assert_produces_warning(FutureWarning):\n",
    "            result = self.f2(old=x)\n",
    "        self.assertEqual(result, 'bogus')\n",
    "\n",
    "    def test_callable_deprecate_kwarg(self):\n",
    "        x = 5\n",
    "        with tm.assert_produces_warning(FutureWarning):\n",
    "            result = self.f3(old=x)\n",
    "        self.assertEqual(result, x + 1)\n",
    "        with pytest.raises(TypeError):\n",
    "            self.f3(old='hello')\n",
    "\n",
    "    def test_bad_deprecate_kwarg(self):\n",
    "        with pytest.raises(TypeError):\n",
    "            @deprecate_kwarg('old', 'new', 0)\n",
    "            def f4(new=None):\n",
    "                pass\n",
    "\n",
    "\n",
    "def test_rands():\n",
    "    r = tm.rands(10)\n",
    "    assert(len(r) == 10)\n",
    "\n",
    "\n",
    "def test_rands_array():\n",
    "    arr = tm.rands_array(5, size=10)\n",
    "    assert(arr.shape == (10,))\n",
    "    assert(len(arr[0]) == 5)\n",
    "\n",
    "    arr = tm.rands_array(7, size=(10, 10))\n",
    "    assert(arr.shape == (10, 10))\n",
    "    assert(len(arr[1, 1]) == 7)\n",
    "\n",
    "\n",
    "class TestValidateArgs(tm.TestCase):\n",
    "    fname = 'func'\n",
    "\n",
    "    def test_bad_min_fname_arg_count(self):\n",
    "        msg = \"'max_fname_arg_count' must be non-negative\"\n",
    "        with tm.assertRaisesRegexp(ValueError, msg):\n",
    "            validate_args(self.fname, (None,), -1, 'foo')\n",
    "\n",
    "    def test_bad_arg_length_max_value_single(self):\n",
    "        args = (None, None)\n",
    "        compat_args = ('foo',)\n",
    "\n",
    "        min_fname_arg_count = 0\n",
    "        max_length = len(compat_args) + min_fname_arg_count\n",
    "        actual_length = len(args) + min_fname_arg_count\n",
    "        msg = (r\"{fname}\\(\\) takes at most {max_length} \"\n",
    "               r\"argument \\({actual_length} given\\)\"\n",
    "               .format(fname=self.fname, max_length=max_length,\n",
    "                       actual_length=actual_length))\n",
    "\n",
    "        with tm.assertRaisesRegexp(TypeError, msg):\n",
    "            validate_args(self.fname, args,\n",
    "                          min_fname_arg_count,\n",
    "                          compat_args)\n",
    "\n",
    "    def test_bad_arg_length_max_value_multiple(self):\n",
    "        args = (None, None)\n",
    "        compat_args = dict(foo=None)\n",
    "\n",
    "        min_fname_arg_count = 2\n",
    "        max_length = len(compat_args) + min_fname_arg_count\n",
    "        actual_length = len(args) + min_fname_arg_count\n",
    "        msg = (r\"{fname}\\(\\) takes at most {max_length} \"\n",
    "               r\"arguments \\({actual_length} given\\)\"\n",
    "               .format(fname=self.fname, max_length=max_length,\n",
    "                       actual_length=actual_length))\n",
    "\n",
    "        with tm.assertRaisesRegexp(TypeError, msg):\n",
    "            validate_args(self.fname, args,\n",
    "                          min_fname_arg_count,\n",
    "                          compat_args)\n",
    "\n",
    "    def test_not_all_defaults(self):\n",
    "        bad_arg = 'foo'\n",
    "        msg = (\"the '{arg}' parameter is not supported \"\n",
    "               r\"in the pandas implementation of {func}\\(\\)\".\n",
    "               format(arg=bad_arg, func=self.fname))\n",
    "\n",
    "        compat_args = OrderedDict()\n",
    "        compat_args['foo'] = 2\n",
    "        compat_args['bar'] = -1\n",
    "        compat_args['baz'] = 3\n",
    "\n",
    "        arg_vals = (1, -1, 3)\n",
    "\n",
    "        for i in range(1, 3):\n",
    "            with tm.assertRaisesRegexp(ValueError, msg):\n",
    "                validate_args(self.fname, arg_vals[:i], 2, compat_args)\n",
    "\n",
    "    def test_validation(self):\n",
    "        # No exceptions should be thrown\n",
    "        validate_args(self.fname, (None,), 2, dict(out=None))\n",
    "\n",
    "        compat_args = OrderedDict()\n",
    "        compat_args['axis'] = 1\n",
    "        compat_args['out'] = None\n",
    "\n",
    "        validate_args(self.fname, (1, None), 2, compat_args)\n",
    "\n",
    "\n",
    "class TestValidateKwargs(tm.TestCase):\n",
    "    fname = 'func'\n",
    "\n",
    "    def test_bad_kwarg(self):\n",
    "        goodarg = 'f'\n",
    "        badarg = goodarg + 'o'\n",
    "\n",
    "        compat_args = OrderedDict()\n",
    "        compat_args[goodarg] = 'foo'\n",
    "        compat_args[badarg + 'o'] = 'bar'\n",
    "        kwargs = {goodarg: 'foo', badarg: 'bar'}\n",
    "        msg = (r\"{fname}\\(\\) got an unexpected \"\n",
    "               r\"keyword argument '{arg}'\".format(\n",
    "                   fname=self.fname, arg=badarg))\n",
    "\n",
    "        with tm.assertRaisesRegexp(TypeError, msg):\n",
    "            validate_kwargs(self.fname, kwargs, compat_args)\n",
    "\n",
    "    def test_not_all_none(self):\n",
    "        bad_arg = 'foo'\n",
    "        msg = (r\"the '{arg}' parameter is not supported \"\n",
    "               r\"in the pandas implementation of {func}\\(\\)\".\n",
    "               format(arg=bad_arg, func=self.fname))\n",
    "\n",
    "        compat_args = OrderedDict()\n",
    "        compat_args['foo'] = 1\n",
    "        compat_args['bar'] = 's'\n",
    "        compat_args['baz'] = None\n",
    "\n",
    "        kwarg_keys = ('foo', 'bar', 'baz')\n",
    "        kwarg_vals = (2, 's', None)\n",
    "\n",
    "        for i in range(1, 3):\n",
    "            kwargs = dict(zip(kwarg_keys[:i],\n",
    "                              kwarg_vals[:i]))\n",
    "\n",
    "            with tm.assertRaisesRegexp(ValueError, msg):\n",
    "                validate_kwargs(self.fname, kwargs, compat_args)\n",
    "\n",
    "    def test_validation(self):\n",
    "        # No exceptions should be thrown\n",
    "        compat_args = OrderedDict()\n",
    "        compat_args['f'] = None\n",
    "        compat_args['b'] = 1\n",
    "        compat_args['ba'] = 's'\n",
    "        kwargs = dict(f=None, b=1)\n",
    "        validate_kwargs(self.fname, kwargs, compat_args)\n",
    "\n",
    "    def test_validate_bool_kwarg(self):\n",
    "        arg_names = ['inplace', 'copy']\n",
    "        invalid_values = [1, \"True\", [1, 2, 3], 5.0]\n",
    "        valid_values = [True, False, None]\n",
    "\n",
    "        for name in arg_names:\n",
    "            for value in invalid_values:\n",
    "                with tm.assertRaisesRegexp(ValueError,\n",
    "                                           (\"For argument \\\"%s\\\" expected \"\n",
    "                                            \"type bool, received type %s\") %\n",
    "                                           (name, type(value).__name__)):\n",
    "                    validate_bool_kwarg(value, name)\n",
    "\n",
    "            for value in valid_values:\n",
    "                assert validate_bool_kwarg(value, name) == value\n",
    "\n",
    "\n",
    "class TestValidateKwargsAndArgs(tm.TestCase):\n",
    "    fname = 'func'\n",
    "\n",
    "    def test_invalid_total_length_max_length_one(self):\n",
    "        compat_args = ('foo',)\n",
    "        kwargs = {'foo': 'FOO'}\n",
    "        args = ('FoO', 'BaZ')\n",
    "\n",
    "        min_fname_arg_count = 0\n",
    "        max_length = len(compat_args) + min_fname_arg_count\n",
    "        actual_length = len(kwargs) + len(args) + min_fname_arg_count\n",
    "        msg = (r\"{fname}\\(\\) takes at most {max_length} \"\n",
    "               r\"argument \\({actual_length} given\\)\"\n",
    "               .format(fname=self.fname, max_length=max_length,\n",
    "                       actual_length=actual_length))\n",
    "\n",
    "        with tm.assertRaisesRegexp(TypeError, msg):\n",
    "            validate_args_and_kwargs(self.fname, args, kwargs,\n",
    "                                     min_fname_arg_count,\n",
    "                                     compat_args)\n",
    "\n",
    "    def test_invalid_total_length_max_length_multiple(self):\n",
    "        compat_args = ('foo', 'bar', 'baz')\n",
    "        kwargs = {'foo': 'FOO', 'bar': 'BAR'}\n",
    "        args = ('FoO', 'BaZ')\n",
    "\n",
    "        min_fname_arg_count = 2\n",
    "        max_length = len(compat_args) + min_fname_arg_count\n",
    "        actual_length = len(kwargs) + len(args) + min_fname_arg_count\n",
    "        msg = (r\"{fname}\\(\\) takes at most {max_length} \"\n",
    "               r\"arguments \\({actual_length} given\\)\"\n",
    "               .format(fname=self.fname, max_length=max_length,\n",
    "                       actual_length=actual_length))\n",
    "\n",
    "        with tm.assertRaisesRegexp(TypeError, msg):\n",
    "            validate_args_and_kwargs(self.fname, args, kwargs,\n",
    "                                     min_fname_arg_count,\n",
    "                                     compat_args)\n",
    "\n",
    "    def test_no_args_with_kwargs(self):\n",
    "        bad_arg = 'bar'\n",
    "        min_fname_arg_count = 2\n",
    "\n",
    "        compat_args = OrderedDict()\n",
    "        compat_args['foo'] = -5\n",
    "        compat_args[bad_arg] = 1\n",
    "\n",
    "        msg = (r\"the '{arg}' parameter is not supported \"\n",
    "               r\"in the pandas implementation of {func}\\(\\)\".\n",
    "               format(arg=bad_arg, func=self.fname))\n",
    "\n",
    "        args = ()\n",
    "        kwargs = {'foo': -5, bad_arg: 2}\n",
    "        tm.assertRaisesRegexp(ValueError, msg,\n",
    "                              validate_args_and_kwargs,\n",
    "                              self.fname, args, kwargs,\n",
    "                              min_fname_arg_count, compat_args)\n",
    "\n",
    "        args = (-5, 2)\n",
    "        kwargs = {}\n",
    "        tm.assertRaisesRegexp(ValueError, msg,\n",
    "                              validate_args_and_kwargs,\n",
    "                              self.fname, args, kwargs,\n",
    "                              min_fname_arg_count, compat_args)\n",
    "\n",
    "    def test_duplicate_argument(self):\n",
    "        min_fname_arg_count = 2\n",
    "        compat_args = OrderedDict()\n",
    "        compat_args['foo'] = None\n",
    "        compat_args['bar'] = None\n",
    "        compat_args['baz'] = None\n",
    "        kwargs = {'foo': None, 'bar': None}\n",
    "        args = (None,)  # duplicate value for 'foo'\n",
    "\n",
    "        msg = (r\"{fname}\\(\\) got multiple values for keyword \"\n",
    "               r\"argument '{arg}'\".format(fname=self.fname, arg='foo'))\n",
    "\n",
    "        with tm.assertRaisesRegexp(TypeError, msg):\n",
    "            validate_args_and_kwargs(self.fname, args, kwargs,\n",
    "                                     min_fname_arg_count,\n",
    "                                     compat_args)\n",
    "\n",
    "    def test_validation(self):\n",
    "        # No exceptions should be thrown\n",
    "        compat_args = OrderedDict()\n",
    "        compat_args['foo'] = 1\n",
    "        compat_args['bar'] = None\n",
    "        compat_args['baz'] = -2\n",
    "        kwargs = {'baz': -2}\n",
    "        args = (1, None)\n",
    "\n",
    "        min_fname_arg_count = 2\n",
    "        validate_args_and_kwargs(self.fname, args, kwargs,\n",
    "                                 min_fname_arg_count,\n",
    "                                 compat_args)\n",
    "\n",
    "\n",
    "class TestMove(tm.TestCase):\n",
    "\n",
    "    def test_cannot_create_instance_of_stolenbuffer(self):\n",
    "        \"\"\"Stolen buffers need to be created through the smart constructor\n",
    "        ``move_into_mutable_buffer`` which has a bunch of checks in it.\n",
    "        \"\"\"\n",
    "        msg = \"cannot create 'pandas.util._move.stolenbuf' instances\"\n",
    "        with tm.assertRaisesRegexp(TypeError, msg):\n",
    "            stolenbuf()\n",
    "\n",
    "    def test_more_than_one_ref(self):\n",
    "        \"\"\"Test case for when we try to use ``move_into_mutable_buffer`` when\n",
    "        the object being moved has other references.\n",
    "        \"\"\"\n",
    "        b = b'testing'\n",
    "\n",
    "        with pytest.raises(BadMove) as e:\n",
    "            def handle_success(type_, value, tb):\n",
    "                self.assertIs(value.args[0], b)\n",
    "                return type(e).handle_success(e, type_, value, tb)  # super\n",
    "\n",
    "            e.handle_success = handle_success\n",
    "            move_into_mutable_buffer(b)\n",
    "\n",
    "    def test_exactly_one_ref(self):\n",
    "        \"\"\"Test case for when the object being moved has exactly one reference.\n",
    "        \"\"\"\n",
    "        b = b'testing'\n",
    "\n",
    "        # We need to pass an expression on the stack to ensure that there are\n",
    "        # not extra references hanging around. We cannot rewrite this test as\n",
    "        #   buf = b[:-3]\n",
    "        #   as_stolen_buf = move_into_mutable_buffer(buf)\n",
    "        # because then we would have more than one reference to buf.\n",
    "        as_stolen_buf = move_into_mutable_buffer(b[:-3])\n",
    "\n",
    "        # materialize as bytearray to show that it is mutable\n",
    "        self.assertEqual(bytearray(as_stolen_buf), b'test')\n",
    "\n",
    "    @pytest.mark.skipif(\n",
    "        sys.version_info[0] > 2,\n",
    "        reason='bytes objects cannot be interned in py3',\n",
    "    )\n",
    "    def test_interned(self):\n",
    "        salt = uuid4().hex\n",
    "\n",
    "        def make_string():\n",
    "            # We need to actually create a new string so that it has refcount\n",
    "            # one. We use a uuid so that we know the string could not already\n",
    "            # be in the intern table.\n",
    "            return ''.join(('testing: ', salt))\n",
    "\n",
    "        # This should work, the string has one reference on the stack.\n",
    "        move_into_mutable_buffer(make_string())\n",
    "\n",
    "        refcount = [None]  # nonlocal\n",
    "\n",
    "        def ref_capture(ob):\n",
    "            # Subtract two because those are the references owned by this\n",
    "            # frame:\n",
    "            #   1. The local variables of this stack frame.\n",
    "            #   2. The python data stack of this stack frame.\n",
    "            refcount[0] = sys.getrefcount(ob) - 2\n",
    "            return ob\n",
    "\n",
    "        with pytest.raises(BadMove):\n",
    "            # If we intern the string it will still have one reference but now\n",
    "            # it is in the intern table so if other people intern the same\n",
    "            # string while the mutable buffer holds the first string they will\n",
    "            # be the same instance.\n",
    "            move_into_mutable_buffer(ref_capture(intern(make_string())))  # noqa\n",
    "\n",
    "        self.assertEqual(\n",
    "            refcount[0],\n",
    "            1,\n",
    "            msg='The BadMove was probably raised for refcount reasons instead'\n",
    "            ' of interning reasons',\n",
    "        )\n",
    "\n",
    "\n",
    "def test_numpy_errstate_is_default():\n",
    "    # The defaults since numpy 1.6.0\n",
    "    expected = {'over': 'warn', 'divide': 'warn', 'invalid': 'warn',\n",
    "                'under': 'ignore'}\n",
    "    import numpy as np\n",
    "    from pandas.compat import numpy  # noqa\n",
    "    # The errstate should be unchanged after that import.\n",
    "    assert np.geterr() == expected\n",
    "\n",
    "\n",
    "class TestLocaleUtils(tm.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        super(TestLocaleUtils, cls).setUpClass()\n",
    "        cls.locales = tm.get_locales()\n",
    "\n",
    "        if not cls.locales:\n",
    "            pytest.skip(\"No locales found\")\n",
    "\n",
    "        tm._skip_if_windows()\n",
    "\n",
    "    @classmethod\n",
    "    def tearDownClass(cls):\n",
    "        super(TestLocaleUtils, cls).tearDownClass()\n",
    "        del cls.locales\n",
    "\n",
    "    def test_get_locales(self):\n",
    "        # all systems should have at least a single locale\n",
    "        assert len(tm.get_locales()) > 0\n",
    "\n",
    "    def test_get_locales_prefix(self):\n",
    "        if len(self.locales) == 1:\n",
    "            pytest.skip(\"Only a single locale found, no point in \"\n",
    "                        \"trying to test filtering locale prefixes\")\n",
    "        first_locale = self.locales[0]\n",
    "        assert len(tm.get_locales(prefix=first_locale[:2])) > 0\n",
    "\n",
    "    def test_set_locale(self):\n",
    "        if len(self.locales) == 1:\n",
    "            pytest.skip(\"Only a single locale found, no point in \"\n",
    "                        \"trying to test setting another locale\")\n",
    "\n",
    "        if all(x is None for x in CURRENT_LOCALE):\n",
    "            # Not sure why, but on some travis runs with pytest,\n",
    "            # getlocale() returned (None, None).\n",
    "            pytest.skip(\"CURRENT_LOCALE is not set.\")\n",
    "\n",
    "        if LOCALE_OVERRIDE is None:\n",
    "            lang, enc = 'it_CH', 'UTF-8'\n",
    "        elif LOCALE_OVERRIDE == 'C':\n",
    "            lang, enc = 'en_US', 'ascii'\n",
    "        else:\n",
    "            lang, enc = LOCALE_OVERRIDE.split('.')\n",
    "\n",
    "        enc = codecs.lookup(enc).name\n",
    "        new_locale = lang, enc\n",
    "\n",
    "        if not tm._can_set_locale(new_locale):\n",
    "            with pytest.raises(locale.Error):\n",
    "                with tm.set_locale(new_locale):\n",
    "                    pass\n",
    "        else:\n",
    "            with tm.set_locale(new_locale) as normalized_locale:\n",
    "                new_lang, new_enc = normalized_locale.split('.')\n",
    "                new_enc = codecs.lookup(enc).name\n",
    "                normalized_locale = new_lang, new_enc\n",
    "                self.assertEqual(normalized_locale, new_locale)\n",
    "\n",
    "        current_locale = locale.getlocale()\n",
    "        self.assertEqual(current_locale, CURRENT_LOCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pytest\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pandas import Series, Timestamp\n",
    "from pandas.compat import range, lmap\n",
    "import pandas.core.common as com\n",
    "import pandas.util.testing as tm\n",
    "\n",
    "\n",
    "def test_mut_exclusive():\n",
    "    msg = \"mutually exclusive arguments: '[ab]' and '[ab]'\"\n",
    "    with tm.assertRaisesRegexp(TypeError, msg):\n",
    "        com._mut_exclusive(a=1, b=2)\n",
    "    assert com._mut_exclusive(a=1, b=None) == 1\n",
    "    assert com._mut_exclusive(major=None, major_axis=None) is None\n",
    "\n",
    "\n",
    "def test_get_callable_name():\n",
    "    from functools import partial\n",
    "    getname = com._get_callable_name\n",
    "\n",
    "    def fn(x):\n",
    "        return x\n",
    "\n",
    "    lambda_ = lambda x: x\n",
    "    part1 = partial(fn)\n",
    "    part2 = partial(part1)\n",
    "\n",
    "    class somecall(object):\n",
    "\n",
    "        def __call__(self):\n",
    "            return x  # noqa\n",
    "\n",
    "    assert getname(fn) == 'fn'\n",
    "    assert getname(lambda_)\n",
    "    assert getname(part1) == 'fn'\n",
    "    assert getname(part2) == 'fn'\n",
    "    assert getname(somecall()) == 'somecall'\n",
    "    assert getname(1) is None\n",
    "\n",
    "\n",
    "def test_any_none():\n",
    "    assert (com._any_none(1, 2, 3, None))\n",
    "    assert (not com._any_none(1, 2, 3, 4))\n",
    "\n",
    "\n",
    "def test_all_not_none():\n",
    "    assert (com._all_not_none(1, 2, 3, 4))\n",
    "    assert (not com._all_not_none(1, 2, 3, None))\n",
    "    assert (not com._all_not_none(None, None, None, None))\n",
    "\n",
    "\n",
    "def test_iterpairs():\n",
    "    data = [1, 2, 3, 4]\n",
    "    expected = [(1, 2), (2, 3), (3, 4)]\n",
    "\n",
    "    result = list(com.iterpairs(data))\n",
    "\n",
    "    assert (result == expected)\n",
    "\n",
    "\n",
    "def test_split_ranges():\n",
    "    def _bin(x, width):\n",
    "        \"return int(x) as a base2 string of given width\"\n",
    "        return ''.join(str((x >> i) & 1) for i in range(width - 1, -1, -1))\n",
    "\n",
    "    def test_locs(mask):\n",
    "        nfalse = sum(np.array(mask) == 0)\n",
    "\n",
    "        remaining = 0\n",
    "        for s, e in com.split_ranges(mask):\n",
    "            remaining += e - s\n",
    "\n",
    "            assert 0 not in mask[s:e]\n",
    "\n",
    "        # make sure the total items covered by the ranges are a complete cover\n",
    "        assert remaining + nfalse == len(mask)\n",
    "\n",
    "    # exhaustively test all possible mask sequences of length 8\n",
    "    ncols = 8\n",
    "    for i in range(2 ** ncols):\n",
    "        cols = lmap(int, list(_bin(i, ncols)))  # count up in base2\n",
    "        mask = [cols[i] == 1 for i in range(len(cols))]\n",
    "        test_locs(mask)\n",
    "\n",
    "    # base cases\n",
    "    test_locs([])\n",
    "    test_locs([0])\n",
    "    test_locs([1])\n",
    "\n",
    "\n",
    "def test_map_indices_py():\n",
    "    data = [4, 3, 2, 1]\n",
    "    expected = {4: 0, 3: 1, 2: 2, 1: 3}\n",
    "\n",
    "    result = com.map_indices_py(data)\n",
    "\n",
    "    assert (result == expected)\n",
    "\n",
    "\n",
    "def test_union():\n",
    "    a = [1, 2, 3]\n",
    "    b = [4, 5, 6]\n",
    "\n",
    "    union = sorted(com.union(a, b))\n",
    "\n",
    "    assert ((a + b) == union)\n",
    "\n",
    "\n",
    "def test_difference():\n",
    "    a = [1, 2, 3]\n",
    "    b = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "    inter = sorted(com.difference(b, a))\n",
    "\n",
    "    assert ([4, 5, 6] == inter)\n",
    "\n",
    "\n",
    "def test_intersection():\n",
    "    a = [1, 2, 3]\n",
    "    b = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "    inter = sorted(com.intersection(a, b))\n",
    "\n",
    "    assert (a == inter)\n",
    "\n",
    "\n",
    "def test_groupby():\n",
    "    values = ['foo', 'bar', 'baz', 'baz2', 'qux', 'foo3']\n",
    "    expected = {'f': ['foo', 'foo3'],\n",
    "                'b': ['bar', 'baz', 'baz2'],\n",
    "                'q': ['qux']}\n",
    "\n",
    "    grouped = com.groupby(values, lambda x: x[0])\n",
    "\n",
    "    for k, v in grouped:\n",
    "        assert v == expected[k]\n",
    "\n",
    "\n",
    "def test_random_state():\n",
    "    import numpy.random as npr\n",
    "    # Check with seed\n",
    "    state = com._random_state(5)\n",
    "    assert state.uniform() == npr.RandomState(5).uniform()\n",
    "\n",
    "    # Check with random state object\n",
    "    state2 = npr.RandomState(10)\n",
    "    assert (com._random_state(state2).uniform() ==\n",
    "            npr.RandomState(10).uniform())\n",
    "\n",
    "    # check with no arg random state\n",
    "    assert com._random_state() is np.random\n",
    "\n",
    "    # Error for floats or strings\n",
    "    with pytest.raises(ValueError):\n",
    "        com._random_state('test')\n",
    "\n",
    "    with pytest.raises(ValueError):\n",
    "        com._random_state(5.5)\n",
    "\n",
    "\n",
    "def test_maybe_match_name():\n",
    "\n",
    "    matched = com._maybe_match_name(\n",
    "        Series([1], name='x'), Series(\n",
    "            [2], name='x'))\n",
    "    assert (matched == 'x')\n",
    "\n",
    "    matched = com._maybe_match_name(\n",
    "        Series([1], name='x'), Series(\n",
    "            [2], name='y'))\n",
    "    assert (matched is None)\n",
    "\n",
    "    matched = com._maybe_match_name(Series([1]), Series([2], name='x'))\n",
    "    assert (matched is None)\n",
    "\n",
    "    matched = com._maybe_match_name(Series([1], name='x'), Series([2]))\n",
    "    assert (matched is None)\n",
    "\n",
    "    matched = com._maybe_match_name(Series([1], name='x'), [2])\n",
    "    assert (matched == 'x')\n",
    "\n",
    "    matched = com._maybe_match_name([1], Series([2], name='y'))\n",
    "    assert (matched == 'y')\n",
    "\n",
    "\n",
    "def test_dict_compat():\n",
    "    data_datetime64 = {np.datetime64('1990-03-15'): 1,\n",
    "                       np.datetime64('2015-03-15'): 2}\n",
    "    data_unchanged = {1: 2, 3: 4, 5: 6}\n",
    "    expected = {Timestamp('1990-3-15'): 1, Timestamp('2015-03-15'): 2}\n",
    "    assert (com._dict_compat(data_datetime64) == expected)\n",
    "    assert (com._dict_compat(expected) == expected)\n",
    "    assert (com._dict_compat(data_unchanged) == data_unchanged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}